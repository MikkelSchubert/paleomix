# SPDX-License-Identifier: MIT
# SPDX-FileCopyrightText: 2023 Mikkel Schubert <mikkelsch@gmail.com>
from __future__ import annotations

import logging
import string
from collections import defaultdict
from collections.abc import Iterable

from paleomix.common import yaml
from paleomix.common.bamfiles import BAM_PLATFORMS
from paleomix.common.fileutils import read_tsv
from paleomix.common.makefile import (
    REQUIRED_VALUE,
    And,
    FASTQPath,
    IsBoolean,
    IsFloat,
    IsInt,
    IsListOf,
    IsNone,
    IsStr,
    MakefileError,
    Not,
    Or,
    SpecTree,
    StringEndsWith,
    StringStartsWith,
    ValueIn,
    ValuesIntersect,
    ValuesSubsetOf,
    process_makefile,
)


def load_project(filename, sample_table):
    try:
        with open(filename) as handle:
            data = yaml.safe_load(handle)
    except yaml.YAMLError as error:
        raise MakefileError(error)

    # Fill out any values using user-specified constants; this must be done prior
    # to processing and validating the structure, since the constant names themselves
    # may not be valid values where they are used.
    data = _replace_constants(data)

    if sample_table is not None:
        _load_sample_table(data, sample_table)

    data = process_makefile(data, _VALIDATION)

    return _post_process_project(data)


# Valid names for genomes, library, and lanes
_VALID_NAME = And(
    IsStr(),
    ValuesSubsetOf(
        string.ascii_letters + string.digits + "._-",
        description="characters a-z, A-Z, 0-9, '.', '_', and '-' allowed",
    ),
)

# Valid names for samples. Must not overlap with special folders
_VALID_SAMPLE_NAME = And(_VALID_NAME, Not(ValueIn(["reports"])))

# Valid paths for genomes; this is a conservative set of characters chosen to ensure
# that they won't cause problems with poorly written tools and scripts, such as Bash
# scripts that do not quote filenames.
_VALID_GENOME_PATH = And(
    IsStr(),
    Not(ValuesIntersect('\\:?"<>|() \t\n\v\f\r')),
    default=REQUIRED_VALUE,
)

# Values that may used for generic command-line options
_COMMAND_LINE_VALUE = Or(
    IsListOf(IsStr, IsInt, IsFloat), Or(IsStr, IsInt, IsFloat, IsNone)
)

# Command-line options starting with double-dashes; this is done to ensure that only
# one variaint of a command-line option is used (i.e. not both -t and --threads), and
# to make project files more readable.
_LONG_COMMAND_LINE_OPTIONS: SpecTree = {
    StringStartsWith("--"): _COMMAND_LINE_VALUE,
}

# Command-line options starting with single-dashes; should only be used if the tool
# does not support --long-form command-line options.
_SHORT_COMMAND_LINE_OPTIONS: SpecTree = {
    StringStartsWith("-"): _COMMAND_LINE_VALUE,
}


_VALIDATION: SpecTree = {
    "Samples": {
        _VALID_SAMPLE_NAME: {  # Sample
            _VALID_NAME: {  # Library
                _VALID_NAME: FASTQPath(paired_end=True),  # Lane
            },
        },
    },
    "ExternalSamples": {
        _VALID_SAMPLE_NAME: {
            "BAM": Or(
                StringEndsWith(".bam"),
                StringEndsWith(".cram"),
                IsNone,
                default=None,
            ),
            "gVCF": Or(StringEndsWith(".vcf.gz"), IsNone, default=None),
        }
    },
    "Genome": {
        "Name": _VALID_NAME,
        "Path": _VALID_GENOME_PATH,
        "ScatterCount": {
            "Haplotyping": IsInt(default=10),
            "Genotyping": IsInt(default=100),
        },
        "SubdivisionMode": ValueIn(
            (
                "INTERVAL_SUBDIVISION",
                "BALANCING_WITHOUT_INTERVAL_SUBDIVISION",
                "BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW",
            ),
            default="INTERVAL_SUBDIVISION",
        ),
    },
    "Settings": {
        "Metadata": {
            "Platform": ValueIn(BAM_PLATFORMS, default=REQUIRED_VALUE),
        },
        "Constants": {
            IsStr: _COMMAND_LINE_VALUE,
        },
        # Common options passe to the JRE
        "JavaOptions": {
            StringStartsWith("-X"): IsNone,
        },
        "Preprocessing": {
            # Quality metrics performed prior to pre-processsing
            "FastQC": _LONG_COMMAND_LINE_OPTIONS,
            # Merging, trimming, and filtering of reads
            "Fastp": _LONG_COMMAND_LINE_OPTIONS,
            # Merging of reports generated by FastQC and Fastp
            "MultiQC": _LONG_COMMAND_LINE_OPTIONS,
        },
        "ReadMapping": {
            "StorageFormat": ValueIn(("bam", "cram"), default="bam"),
            # FIXME: Should be grouped with other mapping-step programs (fixmate, etc.)
            "BWAMem": _SHORT_COMMAND_LINE_OPTIONS,
            "PCRDuplicates": {
                "mode": ValueIn(("mark", "filter", "skip"), default="mark"),
            },
            "BaseRecalibrator": {
                StringStartsWith("--"): _COMMAND_LINE_VALUE,
                "--known-sites": IsStr(default=REQUIRED_VALUE),
            },
            "ApplyBQSR": {
                "Enabled": IsBoolean(default=False),
                StringStartsWith("--"): _COMMAND_LINE_VALUE,
            },
        },
        "Genotyping": {
            "HaplotypeCaller": _LONG_COMMAND_LINE_OPTIONS,
            "ReblockGVCFs": {
                "Enabled": IsBoolean(default=False),
                StringStartsWith("-"): _COMMAND_LINE_VALUE,
            },
            "CombineGVCFs": {
                "Method": ValueIn(("bcftools", "GATK"), default="GATK"),
                "BCFTools": {
                    StringStartsWith("-"): _COMMAND_LINE_VALUE,
                },
                "GATK": {
                    StringStartsWith("-"): _COMMAND_LINE_VALUE,
                },
            },
            "GenotypeGVCFs": _LONG_COMMAND_LINE_OPTIONS,
            "VariantRecalibrator": {
                "Enabled": IsBoolean(default=True),
                "INDEL": _LONG_COMMAND_LINE_OPTIONS,
                "SNP": _LONG_COMMAND_LINE_OPTIONS,
            },
            "ApplyVQSR": {
                "Enabled": IsBoolean(default=True),
                "INDEL": _LONG_COMMAND_LINE_OPTIONS,
                "SNP": _LONG_COMMAND_LINE_OPTIONS,
            },
        },
    },
}


########################################################################################
# Pre- and post-processing of projects


def _replace_constants(data):
    settings = data.get("Settings", {})
    constants = settings.pop("Constants", {})
    if not isinstance(constants, dict):
        # Invalid constants will be caught during global processing
        return None

    # Validate user-supplied constants; the structure is replicated to ensure that
    # error messages give the correct path into the settings structure
    process_makefile(
        {"Settings": {"Constants": constants}},
        {"Settings": {"Constants": {IsStr: _COMMAND_LINE_VALUE}}},
    )
    constants = {f"${{{key}}}": value for key, value in constants.items()}
    if not constants:
        return None

    data["Settings"] = _replace_constants_recursive(settings, constants)

    return data


def _replace_constants_recursive(data, constants):
    if isinstance(data, dict):
        return {
            _replace_constants_recursive(key, constants): _replace_constants_recursive(
                value, constants
            )
            for key, value in data.items()
        }
    elif isinstance(data, list):
        return [_replace_constants_recursive(value, constants) for value in data]
    elif isinstance(data, str):
        return constants.get(data, data)
    else:
        return data


def _post_process_project(data):
    post_processing_steps = [
        _process_fastq_paths,
        _process_sample_names,
        _process_gatk_resources,
        _process_recalibrator_settings,
    ]

    any_errors = False
    for mangle_func in post_processing_steps:
        if not mangle_func(data):
            any_errors = True

    if any_errors:
        raise MakefileError("Invalid settings in project")

    return data


def _process_fastq_paths(data):
    for libraries in data["Samples"].values():
        for lanes in libraries.values():
            for lane, filename in lanes.items():
                lanes[lane] = {
                    1: FASTQPath.format(filename, 1),
                    2: FASTQPath.format(filename, 2),
                }

    return True


def _process_sample_names(data) -> bool:
    log = logging.getLogger(__name__)

    names: dict[str, list[tuple[str, str]]] = defaultdict(list)
    for key in ("Samples", "ExternalSamples"):
        for name in data[key]:
            names[name.lower()].append((name, key))

    any_errors = False
    for values in names.values():
        if len(values) > 1:
            desc = [f"sample {name!r} in {section!r}" for name, section in values]
            log.error(
                "Found %i samples with too similar names: %s",
                len(desc),
                ", ".join(desc),
            )
            any_errors = True

    return not any_errors


def _process_gatk_resources(data):
    any_errors = False
    log = logging.getLogger(__name__)
    # Validate resource files used by VariantRecalibrator
    for mode, options in data["Settings"]["Genotyping"]["VariantRecalibrator"].items():
        if mode not in ("SNP", "INDEL"):
            continue

        found_any = False
        for key, value in options.items():
            # Keys take the form `--resource` and `--resource:${settings}`
            if key == "--resource" or key.startswith("--resource:"):
                if not (isinstance(value, str) and value.endswith(".vcf.gz")):
                    any_errors = True
                    log.error(
                        "Invalid %s path for %s recalibrator; expected a bgzip "
                        "compressed VCF file (*.vcf.gz) but found %r",
                        key,
                        mode,
                        value,
                    )

                found_any = True

        if not found_any:
            log.error("No --resource files specified for %s recalibrator", mode)
            any_errors = True

    return not any_errors


def _process_recalibrator_settings(data):
    # ApplyVQSR relies on files created by the VariantRecalibrator step. For simplicity
    # we require that both be enabled for ApplyVQSR to be carried out. It would be
    # possible to run ApplyVQSR with the prior step disabled, provided that the models
    # had been built, but this would result in unexpected behavior if upstream files
    # changed (models not being updated).
    genotyping = data["Settings"]["Genotyping"]
    if (
        not genotyping["VariantRecalibrator"]["Enabled"]
        and genotyping["ApplyVQSR"]["Enabled"]
    ):
        genotyping["ApplyVQSR"]["Enabled"] = False
        log = logging.getLogger(__name__)
        log.warning(
            "GATK variant recalibration (ApplyVQSR) is enabled, but model building "
            "(VariantRecalibrator) is disabled. Variant recalibration will NOT be "
            "performed!"
        )

    return True


def _get_or_set_dicts(
    data: object,
    keys: Iterable[str],
) -> object:
    for key in keys:
        # Type errors are ignored here, since they will be caught during validation
        if not isinstance(data, dict):
            return None

        value = data.get(key)
        if value is None:
            value = data[key] = {}

        data = value

    return data


def _load_sample_table(data, sample_table) -> None:
    """
    Load samples from a TSV file and inject them into the project dict; this only
    checks for duplicate keys, since everything else will get caught in the subsequent
    validation step.
    """

    def _add_sample(row: dict[str, str]) -> None:
        lanes = _get_or_set_dicts(data, ("Samples", row["Sample"], row["Library"]))
        if isinstance(lanes, dict):
            if row["Lane"] in lanes:
                raise MakefileError(
                    f"Lane {row['Sample']!r} > {row['Library']!r} > "
                    f"{row['Lane']!r} has been specified multiple times"
                )

            lanes[row["Lane"]] = row["Files"]

    reader = iter(read_tsv(sample_table))
    try:
        row = next(reader)
        missing_columns = {"Sample", "Library", "Lane", "Files"} - set(row)
        if missing_columns:
            raise MakefileError(
                f"Sample table {sample_table!r} is missing columns "
                f"{', '.join(missing_columns)}"
            )

        _add_sample(row)
        for row in reader:
            _add_sample(row)
    except ValueError as error:
        raise MakefileError(f"Error reading samples from {sample_table!r}: {error}")
    except StopIteration:
        return
